

# 统计学习及监督学习概论

统计学习方法可以概括如下：

从给定的、有限的、用于学习的训练数据(training data)集合出发，假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数的集合，称为假设空间(hypothesis)；应用某个评价标准(evaluation)，从假设空间中选取一个最优模型，使它对已知的训练数据及未知的测试数据(test data)在给定的评价准则下有最优的预测；最优模型的选取由算法实现.。这样，统计学习方法包括模型的假设空间、模型选择的准则以及模型学习的算法，统称其为统计学习的三要素，简称为模型(model)、策略(strategy)和算法(algorithm)。

实现统计学习方法的步骤如下：

(1)：得到一个有限的训练数据集合；

(2)：确定包含所有可能的模型的假设空间，即学习模型的集合；

(3)：确定模型选择的准则，即学习的策略；

(4)：实现求解最优模型的算法，即学习的算法；

(5)：通过学习方法选择最优模型；

(6)：利用学习的最优模型对新数据进行预测或分析。


# k近邻法

k近邻法(k-nearest neighbor,k-NN)

$L_p$距离($L_p$ distance):设 $\chi$ 是 $n$ 维实数向量空间 $\mathbb{R}^n,x_i,x_j\in \chi,x_i=(x_i^{(1)},x_i^{(2)},\cdots,x_i^{(n)})^\mathrm{T},x_j=$,则$x_i,x_j$的$L_p$距离定义为：

$$
L_p(x_i,x_j)
=\bigg(\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)} |^p \bigg)^\frac{1}{p}
$$

两种特殊情况：

当$p=1,$

$$
L_1(x_i,x_j)
=\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)} |
$$

$L_1$称为曼哈顿距离(Manhattan distance)

当$p=2,$

$$
L_2(x_i,x_j)
=\bigg(\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)} |^2 \bigg)^\frac{1}{2}
$$

$L_2$称为欧氏距离(Euclidean distance)


当$p=\infty,$

$$
L_\infty(x_i,x_j)
=\max_l{|x_i^{(l)}-x_j^{(l)} |}
$$

对$p=\infty$时，$L_p$表达式的证明(太麻烦了，懒得打了)：

由$L_p$距离定义：

$$

\begin{aligned}

L_\infty(x_i,x_j)
&=\lim_{p \to \infty}L_p(x_i,x_j) \\
&=\lim_{p \to \infty}\bigg(\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)} |^p \bigg)^\frac{1}{p} \\
&=\lim_{p \to \infty}

\end{aligned}

$$


# 朴素贝叶斯法

## 基本方法

设输入空间 $\mathcal{X}\subseteq \mathbb{R}^n $ 为 $n$ 维向量的集合，输出空间为类标记集合 $\mathcal{Y}=\{c_1,c_2,\cdots,c_K \}. $ 输入为特征向量 $\vec{x}\in\mathcal{X} ,$ 输出为类标记 $y\in\mathcal{Y}. $ $X$ 是定义在输入空间 $\mathcal{X} $ 上的随机向量，$Y$ 是定义在输出空间 $\mathcal{Y}$ 上的随机变量. $P(X,Y)$ 是 $X,Y$ 的联合概率分布.

设训练数据集：

$$
T=\{(\vec{x}_1,y_1),(\vec{x}_2,y_2),\cdots,(\vec{x}_N,y_N) \}
$$

由 $P(X,Y)$ 独立同分布产生.

朴素贝叶斯法通过数据集 $T$ 学习联合概率分布 $P(X,Y)$

具体来说，学习以下先验概率分布及条件概率分布：

先验概率分布：

$$
P(Y=c_k),~~~k=1,2,\cdots,K
$$

条件概率分布：

$$
P(X=\vec{x}|Y=c_k)
=P( X^{(1)}=\vec{x}^{(1)},X^{(2)}=\vec{x}^{(2)},\cdots,X^{(n)}=\vec{x}^{(n)} | Y=c_k )
$$

由条件概率公式：

$$
P(X=\vec{x},Y=c_k)=P(Y=c_k)P(X=\vec{x} | Y=c_k)
$$

就学习到了联合概率分布 $P(X,Y)$

朴素贝叶斯法对条件概率分布作了条件独立性的假设，即:

$$

\begin{align}

P(X=\vec{x}|Y=c_k)
&\equiv P(X^{(1)}=\vec{x}^{(1)},\cdots,X^{(n)}=\vec{x}^{(n)}|Y=c_k) \\
&=\prod_{j=1}^n P(X^{(j)}=\vec{x}^{(j)}|Y=c_k) 

\end{align}

$$

朴素贝叶斯法进行分类时，对给定的输入 $\vec{x},$ 通过学习到的模型计算后验概率分布：$P(Y=c_k|X=\vec{x});$而由贝叶斯定理(条件概率公式+全概率公式)，有：

$$
P(Y=c_k|X=\vec{x})
=\frac{P(X=\vec{x},Y=c_k)}{P(X=\vec{x})}
=\frac{P(Y=c_k)P(X=\vec{x}|Y=c_k)}{\sum\limits_{i} P(Y=c_i)P(X=\vec{x}|Y=c_i)}
$$

把(2)代入上式，进一步有：

$$
P(Y=c_k|X=\vec{x})
=\frac{P(Y=c_k)\prod\limits_{j}^n P(X^{(j)}=\vec{x}^{(j)}|Y=c_k) }{\sum\limits_{i}P(Y=c_i)\prod\limits_{j}P(X^{(j)}=\vec{x}^{(j)}|Y=c_i)} ,~~~k=1,2,\cdots,K
$$

于是朴素贝叶斯分类器可表示为：

$$
\hat{y}
=f(\vec{x})
=\argmax_{c_k}P(Y=c_k|X=\vec{x})
=\argmax_{c_k}\frac{P(Y=c_k)\prod\limits_{j} P(X^{(j)}=\vec{x}^{(j)}|Y=c_k) }{\sum\limits_{i}P(Y=c_i)\prod\limits_{j}P(X^{(j)}=\vec{x}^{(j)}|Y=c_i)}
$$

注意到，上式中，对所有的 $c_k,$ 分母的值都是相同的，于是,朴素贝叶斯分类器可进一步简化为：

$$
\hat{y}
=\argmax_{c_k}P(Y=c_k)\prod\limits_{j} P(X^{(j)}=\vec{x}^{(j)}|Y=c_k) 
$$

### 后验概率最大化

朴素贝叶斯把实例分到后验概率最大的类中，这等价于期望风险最小化.

把实例分到后验概率最大的类所对应的分类决策函数 $f:$

$$
f(\vec{x})
=\argmax_{y\in\mathcal{Y}}P(Y=y|X=\vec{x})
$$

下面证明，期望风险最小化等价于后验概率最大化.

假设选择$0-1$ 损失函数：

$$
L(Y,f(X))
=

\begin{cases}

1&,Y\ne f(X) \\
0&,Y=f(X)

\end{cases}

$$

设有一组 $(\vec{x},y) ,$ 其中，$\vec{x} $ 是输入的特征向量，$y$ 是与之对应的标签. 设 $\mathcal{F}$ 是假设空间，我们希望找到一个函数 $f\in \mathcal{F},$ 使得在此函数的作用下，输出的预测值 $f(\vec{x})$ 等于或尽可能接近标签 $y $. 我们选择用“期望风险最小”来描述这种“尽可能接近”：


$$

\begin{aligned}

R_{\exp}(f)
&=E[L(Y,f(X))] \\
&=\sum_{i}\sum_{k} L(c_k,f(\vec{x}_i))\cdot P(Y=c_k,X=\vec{x}_i) \\
&=\sum_{k}\sum_{i } L(c_k,f(\vec{x}_i))\cdot P(Y=c_k,X=\vec{x}_i) \\

\end{aligned}

$$


```
期望风险最小就是说，分类决策函数 $f$ 应当输出使得期望风险函数最小的  $y,$即：
```


$$
f(\vec{x})
=\argmin_{y\in\mathcal{Y}} \sum_{k=1}^{K} L(c_k,y)P(Y=c_k|X=\vec{x})
$$

```
其中，$f(X)$ 是分类决策函数. 这时，期望风险函数为：

$$

\begin{aligned}

R_{\exp}(f)
&=E[L(Y,f(X))] \\
&=\sum_{i}\sum_{k} L(c_k,\vec{x}_i)\cdot P(Y=c_k,X=\vec{x}_i) \\
&=\sum_{i}\sum_{k} L(c_k,\vec{x}_i)\cdot P(Y=c_k,X=\vec{x}_i) \\

\end{aligned}

$$
```

### 朴素贝叶斯的参数估计

极大似然估计：

在朴素贝叶斯法中，学习意味着估计 $P(Y=c_k)$ 和 $P(X^{(j)}=x^{(j)}|Y=c_k)$

先验概率 $P(Y=c_k)$ 的极大似然估计是：

$$
P(Y=c_k)
=\frac{\sum\limits_{i=1}^N I(y_i=c_k)}{N},~~~k=1,2,\cdots,K
$$

设第 $j$ 个特征 $\vec{x}^{(j)} $ 可能取值的集合为 $\{a_{j1},a_{j2},\cdots,a_{jS_j} \},$ 条件概率 $P(X^{(j)}=a_{jl}|Y=c_k) $ 的极大似然估计是：

$$
P(X^{(j)}=a_{jl}|Y=c_k)
=\frac{P(X^{(j)}=a_{jl},Y=c_k)}{P(Y=c_k)}
=\frac{\sum\limits_{i=1}^N I(\vec{x}_i^{(j)}=a_{jl},y_i=c_k) /N}{\sum\limits_{i=1}^{N} I(y_i=c_k)/N}
=\frac{\sum\limits_{i=1}^{N} I(\vec{x}_i^{(j)}=a_{jl},y_i=c_k) }{\sum\limits_{i=1}^N I(y_i=c_k)}
$$

$$
j=1,2,\cdots,n;~~~l=1,2,\cdots,S_j;~~~k=1,2,\cdots,K
$$

式中，$\vec{x}_i^{(j)} $ 是第 $i$ 个样本的输入 $\vec{x}_i$ 的第 $j$ 个特征；$a_{jl}$ 是第 $j$ 个特征可能取的第 $l$ 个值；$I$ 为指示函数.

朴素贝叶斯算法(naive Vayes algorithm)

输入：训练数据 $T= \{(\vec{x}_1,y_1),(\vec{x}_2,y_2),\cdots,(\vec{x}_N,y_N) \},$ 其中 $\vec{x}_i=(\vec{x}_i^{(1)},\vec{x}_i^{(2)},\cdots,\vec{x}_i^{(N)})^{\mathrm{T}},$ $\vec{x}_i^{(j)}$ 是第 $i$ 个样本的输入 $\vec{x}_i $ 的第 $j$ 个特征. $\vec{x}_i^{(j)} \in \{a_{j1},a_{j2},\cdots,a_{jS_j} \} ,$ $a_{jl}$ 是第 $j$ 个特征可能取得第 $l$ 个值，$j=1,2,\cdots,n;l=1,2,\cdots,S_j;y_i\in \{c_1,c_2,\cdots,c_K \};$ 实例 $\vec{x}$ 

输出：实例 $\vec{x}$ 的分类

(1)计算先验概率及条件概率

$$
P(Y=c_k)
=\frac{\sum\limits_{i=1}^N I(y_i=c_k)}{N},~~~k=1,2,\cdots,K
$$

$$
P(X^{(j)}=a_{jl}|Y=c_k)
=\frac{\sum\limits_{i=1}^N I(\vec{x}_i^{(j)}=a_{jl},y_i=c_k)}{\sum\limits_{i=1}^N I(y_i=c_k)}
$$

$$
j=1,2,\cdots,n;~~~l=1,2,\cdots,S_j;~~~k=1,2,\cdots K
$$

(2)对于给定的实例 $\vec{x}=(\vec{x}^{(1)},\vec{x}^{(2)},\cdots,\vec{x}^{(n)})^{\mathrm{T}}, $ 计算：

$$
P(Y=c_k)\prod_{j=1}^{n} P(X^{(j)}=\vec{x}^{(j)}|Y=c_k),~~~k=1,2,\cdots,K
$$

(3)确定实例 $\vec{x}$ 的类：

$$
y=\argmax_{c_k} P(Y=c_k)\prod_{j=1}^{n} P(X^{(j)}=\vec{x}^{(j)}|Y=c_k)
$$

例：

试从下表给定的训练数据学习一个朴素贝叶斯分类器，并确定 $\vec{x}=(2,S)^{\mathrm{T}} $ 的类标记 $y.$ 表中，$X^{(1)},X^{(2)}$ 为特征，取值的集合分别为 $A_1=\{1,2,3 \} ,A_2=\{S,M,L \},$ $Y$ 为标记类，$Y\in C=\{1,-1 \}$ 

|训练数据编号|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|$X^{(1)}$ |1|1|1|1|1|2|2|2|2|2|3|3|3|3|3|
|$X^{(2)}$ |S|M|M|S|S|S|M|M|L|L|L|M|M|L|L|
|$Y$ |-1|-1|1|1|-1|-1|-1|1|1|1|1|1|1|1|-1|

根据朴素贝叶斯算法:

(1):

$$
P(Y=1)=\frac{9}{15}
$$

$$
P(Y=-1)=\frac{6}{15}
$$

$$
P(X^{(1)}=1 |Y=1)=\frac{2}{9},
P(X^{(1)}=2 |Y=1)=\frac{3}{9},
P(X^{(1)}=3 |Y=1)=\frac{4}{9}
$$

$$
P(X^{(2)}=S |Y=1)=\frac{1}{9},
P(X^{(2)}=M |Y=1)=\frac{4}{9},
P(X^{(2)}=L |Y=1)=\frac{4}{9}
$$



$$
P(X^{(1)}=1 |Y=-1)=\frac{3}{6},
P(X^{(1)}=2 |Y=-1)=\frac{2}{6},
P(X^{(1)}=3 |Y=-1)=\frac{1}{6}
$$

$$
P(X^{(2)}=S |Y=-1)=\frac{3}{6},
P(X^{(2)}=M |Y=-1)=\frac{2}{6},
P(X^{(2)}=L |Y=-1)=\frac{1}{6}
$$

对于给定的实例 $\vec{x}=(2,S)^{\mathrm{T}}, $计算：

$$
P(Y=1)P(X^{(1)}=2|Y=1)P(X^{(2)}=S|Y=1)
=\frac{9}{15}\cdot\frac{3}{9}\cdot\frac{1}{9}
=\frac{1}{45}
$$

$$
P(Y=-1)P(X^{(1)}=2|Y=-1)P(X^{(2)}=S|Y=-1)
=\frac{6}{15}\cdot\frac{2}{6}\cdot\frac{3}{6}
=\frac{1}{15}
$$

由于 $P(Y=-1)P(X^{(1)}=2|Y=-1)P(X^{(2)}=S|Y=-1)$ 最大，所以 $y=-1$

### 贝叶斯估计

用极大似然估计可能会出现所要估计的概率值为 $0$ 的情况，这时会影响到后验概率的计算结果，使分类产生偏差。为了解决这一问题，我们采用贝叶斯估计。

条件概率的贝叶斯估计是：

$$
P_{\lambda}(X^{(j)}=a_{jl}|Y=c_k)
=\frac{\lambda+\sum\limits_{i=1}^{N} I(\vec{x}_i^{(j)}=a_{jl},y_i=c_k) }{S_j\lambda+\sum\limits_{i=1}^{N} I(y_i=c_k) }
$$

式中，$\lambda\geqslant 0.$贝叶斯估计就是说，在随机变量各个取值的频数上赋予一个正数 $\lambda>0.$ 当 $\lambda=0$ 时就是极大似然估计. 常取 $\lambda=1,$ 这时称为拉普拉斯平滑(Laplacian smoothing). 对任何 $l=1,2,\cdots,S_j;k=1,2,\cdots,K,$ 有：

$$
P_{\lambda}(X^{(j)}=a_{jl}=Y=c_k)>0
$$

$$
\sum_{l=1}^{S_j} P(X^{(j)}=a_{jl}|Y=c_k) =1
$$

上面两式表明，条件概率的贝叶斯估计确实是一种概率分布.

例：

对同样的表，按照拉普拉斯平滑估计概率，即取 $\lambda=1.$

解：

计算概率：

$$
P(Y=1)=\frac{10}{17}
$$

$$
P(Y=-1)=\frac{7}{17}
$$

$$
P(X^{(1)}=1 |Y=1)=\frac{3}{12},
P(X^{(1)}=2 |Y=1)=\frac{4}{12},
P(X^{(1)}=3 |Y=1)=\frac{5}{12}
$$

$$
P(X^{(2)}=S |Y=1)=\frac{2}{12},
P(X^{(2)}=M |Y=1)=\frac{5}{12},
P(X^{(2)}=L |Y=1)=\frac{5}{12}
$$



$$
P(X^{(1)}=1 |Y=-1)=\frac{4}{9},
P(X^{(1)}=2 |Y=-1)=\frac{3}{9},
P(X^{(1)}=3 |Y=-1)=\frac{2}{9}
$$

$$
P(X^{(2)}=S |Y=-1)=\frac{4}{9},
P(X^{(2)}=M |Y=-1)=\frac{3}{9},
P(X^{(2)}=L |Y=-1)=\frac{2}{9}
$$

对于给定的实例 $\vec{x}=(2,S)^{\mathrm{T}}, $计算：

$$
P(Y=1)P(X^{(1)}=2|Y=1)P(X^{(2)}=S|Y=1)
=\frac{10}{17}\cdot\frac{4}{12}\cdot\frac{2}{12}
=\frac{5}{153}
\approx 0.0327
$$

$$
P(Y=-1)P(X^{(1)}=2|Y=-1)P(X^{(2)}=S|Y=-1)
=\frac{7}{17}\cdot\frac{3}{9}\cdot\frac{4}{9}
=\frac{28}{459}
\approx 0.0610
$$

由于 $0.0327<00.0610,$于是 $\hat{y}=-1$

# 决策树

决策树的定义：分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点（node）和有向边（directed edge）组成。结点有两种类型：内部结点（internal node）和叶节点（leaf node）。内部结点表示一个特征或属性，叶节点表示一个类。

用决策树分类，从根结点开始，对实例的某一特征进行测试，根据测试结果，将实例分配到其子结点；这时，每一个子结点对应着该特征的一个取值。如此递归地对实例进行测试并分配，直至达到叶结点。最后将实例分到叶结点地类中。

## 决策树与 if-then 规则

可以将决策树看成一个 if-then 规则的集合。

## 决策树学习

假设给定训练数据集：

$$
D=\{(\vec{x}_1,y_1),(\vec{x}_2,y_2),\cdots,(\vec{x}_N,y_N) \}
$$

其中，$\vec{x}_i=(\vec{x}_i^{(1)},\vec{x}_i^{(2)},\cdots,\vec{x}_i^{(n)})^{\mathrm{T}} $ 为输入实例（特征向量，）$n$ 为特征个数，$y_i\in \{1,2,\cdots,K\}$ 为类标记，$i=1,2,\cdots,N,N$ 为样本容量。决策树学习的目标是根据给定的训练数据集构建一个决策树模型，使它能够对实例进行正确的分类。

决策树学习用损失函数表示这一目标。决策树学习的损失函数通常是正则化的极大似然函数。决策树学习的策略是以损失函数为目标的最小化。

### 熵与条件熵

在信息论与概率统计中，熵（entropy）是表示随机变量不确定性的的度量。设 $X$ 是一个取有限个值得离散随机变量，其概率分布为：

$$
P(X=x_i)
=p_i,~~~i=1,2,\cdots,n
$$

则随机变量 $X$ 的熵的定义为：

$$
H(X)
=-\sum_{i=1}^n p_i\log p_i
$$

规定，若 $p_i=0,$ 则 $p_i\log p_i=0.$ 通常，对数的底取 $2$ 或 $e,$这时 熵的单位分别称为比特（bit）或纳特（nat）。显然，熵只依赖于 $X$ 的分布，而与 $X$ 的取值无关，所以也可将 $X$ 的熵记作 $H(p),$即：

$$
H(p)
=-\sum_{i=1}^{n} p_i\log p_i
$$

熵越大，随机变量的不确定性就越大。

熵的性质：

$$
-\leqslant H(p)\leqslant \log n
$$

设有二维随机变量 $(X,Y),$ 其联合分布律为：

$$
P(X=x_i,Y=y_i)=p_{ij},~~~i=1,2,\cdots;~~~j=1,2,\cdots,m
$$

条件熵 $H(Y|X)$ 表示在随机变量 $X$ 的取值已知的条件下随机变量 $Y$ 的不确定性。随机变量 $X$ 给定的条件下，随机变量 $Y$ 的条件熵（conditional entropy）$H(Y|X)$，定义为 $X$ 给定的条件下，$Y$ 的条件概率分布的熵对 $X$ 的数学期望：

$$
H(Y|X)
=\sum_{i=1}^{n} p_i H(Y|X=x_i)
$$

这里，$p_i=P(X=x_i),i=1,2,\cdots,n$

当熵和条件熵中的概率由数据估计（特别是极大似然估计）得到时，所对应的熵与条件熵分别称为经验熵（empirical entropy）和经验条件熵（empirical conditional entropy）。此时，若






